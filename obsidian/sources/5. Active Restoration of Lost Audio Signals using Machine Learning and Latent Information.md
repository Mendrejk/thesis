[[Active Restoration of Lost Audio Signals using Machine Learning and Latent Information.pdf]]

## Abstract
Digital audio signal reconstruction of a **lost or corrupt segment** using **deep learning algorithms** has been explored intensively in recent years. Nevertheless, prior traditional methods with linear interpolation, phase coding and tone insertion techniques are still in vogue. However, **we found no research work on reconstructing audio signals with the fusion of dithering, steganography, and machine learning regressors**. Therefore, this paper proposes the **combination of steganography, halftoning (dithering), and state-of-the-art shallow and deep learning methods**. The results (including comparing the SPAIN, Autoregressive, deep learning-based, graph-based, and other methods) are evaluated with **three different metrics**. The observations from the results show that the **proposed solution is effective and can enhance the reconstruction of audio signals performed by the side information (e.g., Latent representation) steganography provides.** Moreover, this paper proposes a novel frame- work for reconstruction from heavily compressed embedded audio data using halftoning (i.e., dithering) and machine learning, which we termed the HCR (halftone-based compression and reconstruction). This work may trigger interest in optimising this approach and/or transferring it to different domains (i.e., image reconstruction). Compared to existing methods, we show improvement in the inpainting performance in terms of signal-to-noise ratio (SNR), the objective difference grade (ODG) and Hansen’s audio quality metric. In particular, **our proposed framework outperformed the learning-based methods (D2WGAN and SG) and the traditional statistical algorithms (e.g., SPAIN, TDC, WCP). 3**


## 2 Related Work 
In the work of Khan et al. [4], the authors proposed a modern neuro-evolution algorithm, Enhanced Cartesian Genetic Programming Evolved Artificial Neural Network (ECGPANN), as a predictor of the lost signal samples in real-time. The authors have trained and tested the algorithms on audio speech signal data and evaluated them on the music signal. A deep neural network (DNN)-based regres- sion method was proposed in [5] for a packet loss concealment (PLC) algorithm to predict a missing frame’s characteristics. Two other DNNs were developed for the training by integrating the log-power spectra and phases based on the unsupervised pre-training and supervised fine-tuning. The algorithm then pro- vides the previous frame features to the trained DNN to reconstruct the missing frames. In [1], researchers have analyzed audio gaps (500 - 550 ms) and used Wasserstein Generative Adversarial Network (WGAN) and Dual Discriminator WGAN (D2WGAN) models to reconstruct the lost audio content. In Khan et al. [6], the authors proposed an audio signal reconstruction model called Carte- sian Genetic Programming evolved Artificial Neural Network (CGPANN), which was more efficient than the interpolation-extrapolation techniques. The devel- oped model was robust in recovering signals contaminated with up to 50% noise. In [2], the authors proposed a DNN structure to restore the missing audio con- tent based on the audio gaps. The signals provided in the audio gaps in the DNN structure were time-frequency coefficients (either complex values or magnitude). In the work of Sperschneider et al. [7], the authors presented a delay-less packet- loss concealment (PLC) method for stationary tonal signals, which addresses audio codecs that utilizes a modified discrete cosine transformation (MDCT). In the case of a frame loss, tonal components are identified using the last two obtained spectra and their pitch information. Furthermore, the MDCT coeffi- cients of the tonal components were estimated using phase prediction based on the detection of tonal components. Mokr´y et al. [8] presented an inpainting al- gorithm called SPAIN (SParse Audio INpainter) developed by an adaptation of the successful declipping method, SPADE [9], to the context of audio inpaint- ing. The authors show that the analysis of their algorithm, SPAIN, performs the best in terms of SNR (signal-to-noise ratio) among sparsity-based methods and reaches results on a par with the state-of-the-art Janssen algorithm [10] 4 for audio inpainting. A composite model for audio enhancement that combines the Long Short-Term Memory (LSTM) and the Convolutional Neural Network (CNN) models was proposed in [11]. Perraudin et al. [12], proposed a recon- struction method for the loss of long signals in audio (i.e., Music signals). The 4 Iteratively fits autoregressive models using a gap’s all previous points for forward estimation and all its future points for backward estimation. 4 Z.A. Cheddad and A. Cheddad concealment of such signal defects is based on a graph that encodes signal struc- ture in terms of time-persistent spectral similarity and an intuitive optimization embedding scheme. Mokr´y and Rajmic [13] proposed a heuristic method for compensating for energy loss after running the L1 minimization. Their idea is to take the solution and modify it by entrywise multiplication of the recovered gap in the time domain by a compensation curve in order to increase its amplitude; they termed this approach the Time Domain Compensation (TDC) algorithm.

## 6 Conclusions 
The aim of this paper is to put forward a new framework which proposes the **fusion of audio dither-based steganography with machine/deep learning for the active reconstruction of lost signals.** The results show that the proposed solution is feasible and can enhance the reconstruction of lost audio signals (readers may wish to listen to the audio online, see URL in section 5). We conducted experiments on several types of signal drops of (100ms, 300ms), (500ms to 800ms) and (4000ms, 8000ms (shown online)). **As a proof-of-concept, we can assert that, in general, the LSTM and the RF models are good models to utilise**. Our approach is not meant to replace current inpainting audio methods but rather to assist them by providing latent side information. It can also benefit security systems in protecting audio files from unauthorised manipulation. The paper supplies extensive experiments, which we believe are compelling evidence of the efficacy of our proposed approach, a corollary when combining halftoning, steganography and machine learning. To our knowledge, **we found no similar implementation in the literature for audio missing-segment reconstruction**. Thus, we conclude this paper by stating that the fusion of steganography and state-of-the-art machine learning algorithms can be considered for the active reconstruction of audio signals. However, as we pointed out in the discussion section, **there is room for enhancement, for example, enhancing the algorithm for inverse-halftoning, which is an ill-posed problem**.


# TLDR
Autorzy podchodzą do problemu rekonstrukcji dźwięku w inny sposób -  **combination of steganography, halftoning (dithering), and state-of-the-art shallow and deep learning methods**. 
Osiągają lepsze rezultaty niż znane sieci (**our proposed framework outperformed the learning-based methods (D2WGAN and SG) and the traditional statistical algorithms (e.g., SPAIN, TDC, WCP**).

Nadal jest miejsce na rozwój, szczególnie w dziedzinie algorytmu inverse half-toningu.
